{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enable matplotlib to display in jupyter notebook & import it\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from geopy.geocoders import Nominatim #used in filling missing zipcodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Listings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#listings.csv READING\n",
    "\n",
    "LISTINGS = 'data/listings.csv'\n",
    "\n",
    "#Choose which columns from the csv to read in.\n",
    "listings_cols = ['id',\n",
    "                'host_id',\n",
    "                'neighbourhood_cleansed',\n",
    "                'zipcode',\n",
    "                'latitude',\n",
    "                'longitude',\n",
    "                'property_type',\n",
    "                'room_type',\n",
    "                'accommodates',\n",
    "                'bathrooms',\n",
    "                'amenities',\n",
    "                'price',\n",
    "                'cleaning_fee',\n",
    "                'number_of_reviews',\n",
    "                'first_review',\n",
    "                'review_scores_rating',\n",
    "                'review_scores_accuracy',\n",
    "                'review_scores_cleanliness',\n",
    "                'review_scores_checkin',\n",
    "                'review_scores_communication',\n",
    "                'review_scores_location',\n",
    "                'review_scores_value',\n",
    "                'calculated_host_listings_count',\n",
    "                'reviews_per_month',\n",
    "                'bedrooms',\n",
    "                'beds',\n",
    "                'cancellation_policy',\n",
    "                'instant_bookable',\n",
    "                'minimum_nights'] \n",
    "\n",
    "#Read in data from the csv\n",
    "listings = pd.read_csv(LISTINGS, usecols=listings_cols)\n",
    "\n",
    "#Rename any Columns as needed\n",
    "rename_dict = {'id':'listing_id',\n",
    "              'price':'listed_price'}\n",
    "\n",
    "listings.rename(columns = rename_dict, inplace=True)\n",
    "\n",
    "#use listing_id as index\n",
    "listings.set_index('listing_id', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "#         Cleaning          #\n",
    "#############################\n",
    "\n",
    "# 'zipcode' ##########\n",
    "#Paste this in to zipcode section of cleaning\n",
    "def latLonToZip(lat, lon):\n",
    "    '''Take in a latitude and longitude and return the zipcode for that location'''\n",
    "    geolocator = Nominatim()\n",
    "    try:\n",
    "        location = geolocator.reverse(str(lat)+','+str(lon))\n",
    "        z = re.compile('(\\s)([0-9]{5})(,\\sUnited)')\n",
    "        return z.findall(location[0])[0][1]\n",
    "    except:\n",
    "        print(str(lat)+','+str(lon),'-----',location)\n",
    "        return np.nan\n",
    "    \n",
    "    print(str(lat)+','+str(lon),'-----',location)\n",
    "    return np.nan\n",
    "#Find all missing zippcodes : missing_zipcodes\n",
    "missing_zipcodes = listings[listings.zipcode.isnull()].copy()\n",
    "\n",
    "#update rows that are missing zipcodes using latLonToZip to fill missin\n",
    "listings.zipcode.update(missing_zipcodes.apply(lambda x: latLonToZip(x['latitude'], x['longitude']), axis=1))\n",
    "\n",
    "#Remove 'zip+4' part of any zipcode \n",
    "listings.zipcode = listings.zipcode.apply(lambda x: x[:5])\n",
    "\n",
    "# 'price' --> 'listed_price' ##########\n",
    "listings.listed_price = listings.listed_price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "# 'cleaning_fee' ##########\n",
    "listings.cleaning_fee = listings.cleaning_fee.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "# 'first_review' ##########\n",
    "listings.first_review = pd.to_datetime(listings.first_review)\n",
    "\n",
    "# 'amenities' ##########\n",
    "listings.amenities = listings.amenities.replace('[^\\w,\\s/]+','',regex=True).apply(lambda x: x.split(','))\n",
    "\n",
    "# 'instant_bookable' ##########\n",
    "listings.instant_bookable.replace({'f':False,'t':True}, inplace=True)\n",
    "\n",
    "#Save to Pickle because it preserves the index and types###################\n",
    "listings.to_pickle('data/listings_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Calendar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calendar.csv READING\n",
    "\n",
    "CALENDAR = 'data/calendar.csv'\n",
    "\n",
    "#Read in all columns from calendar.csv : listing_id, date, available, price\n",
    "calendar = pd.read_csv(CALENDAR)\n",
    "\n",
    "\n",
    "#############################\n",
    "#         Cleaning          #\n",
    "#############################\n",
    "\n",
    "# 'date' ##########\n",
    "calendar.date = pd.to_datetime(calendar.date)\n",
    "\n",
    "# 'available' ##########\n",
    "calendar.available.replace({'f':False,'t':True}, inplace=True)\n",
    "\n",
    "# 'price' ##########\n",
    "calendar.price = calendar.price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "#############################\n",
    "#         Augmenting        #\n",
    "#############################\n",
    "\n",
    "#create column to represent the day of the week for each date\n",
    "calendar['day_of_week'] = calendar.date.dt.dayofweek\n",
    "\n",
    "#Fill in missing price values for each listing using mean value for day of week from that listing\n",
    "calendar.price.fillna(calendar.groupby(['listing_id','day_of_week'])['price'].transform(\"mean\"), inplace=True)\n",
    "\n",
    "#create column for revenue generate by property (all prices for occupied days are modeled from mean)\n",
    "calendar['day_revenue'] = np.where(calendar.available, 0.0, calendar.price)\n",
    "\n",
    "#Save to Pickle because it preserves the index and types\n",
    "calendar.to_pickle('data/calendar_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Using Calendar to Augment Listings DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listings = pd.read_pickle('data/listings_cleaned.pkl')\n",
    "calendar = pd.read_pickle('data/calendar_cleaned.pkl')\n",
    "\n",
    "#Create a list of calendars seperated into 4 quarters\n",
    "quarter_dates = ['2016-09-06','2016-12-06','2017-03-06','2017-06-06','2017-09-06']\n",
    "q_cal = [calendar[calendar.date.isin(pd.date_range(quarter_dates[n], quarter_dates[n+1]))] for n in range(4)]\n",
    "\n",
    "#Revnue Per Quarter\n",
    "for n,q in enumerate(q_cal):\n",
    "    listings = listings.join(q_cal[n].groupby('listing_id').day_revenue.sum()).rename(columns={'day_revenue':'q'+str(n+1)+'_revenue'})\n",
    "\n",
    "#Occupancy Per Quarter\n",
    "for n,q in enumerate(q_cal):\n",
    "    q_len = len(pd.date_range(quarter_dates[n], quarter_dates[n+1]))\n",
    "    listings = listings.join((q_len - q_cal[n].groupby('listing_id').available.sum())/q_len).rename(columns={'available':'q'+str(n+1)+'_occupancy_rate'})\n",
    "\n",
    "listings.to_pickle('data/listing_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amenities = list(set([item for item_list in listings.amenities for item in item_list]) \\\n",
    "         - set(['translation missing enhosting_amenity_49','translation missing enhosting_amenity_50','']))\n",
    "\n",
    "amn_frame = pd.DataFrame(index = listings.index)\n",
    "\n",
    "#create the dummy for each amenity and rename the column as you go\n",
    "for amn in amenities:\n",
    "    amn_frame = amn_frame.join(listings.amenities.apply(lambda amns: amn in amns)).rename(columns={'amenities':amn})\n",
    "\n",
    "#listings['analysis_table'] = listings.index\n",
    "#listings['analysis_table'] = pd.DataFrame(listings.analysis_table.map(lambda x: amn_frame.loc[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_table = pd.merge(listings, amn_frame, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_table = pd.merge(analysis_table, pd.get_dummies(analysis_table.room_type), left_index = True, right_index = True)\n",
    "analysis_table = pd.merge(analysis_table, pd.get_dummies(analysis_table.property_type), left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Buzzer/Wireless Intercom',\n",
       " 'Elevator in Building',\n",
       " '24Hour Checkin',\n",
       " 'Safety Card',\n",
       " 'Hangers',\n",
       " 'First Aid Kit',\n",
       " 'Heating',\n",
       " 'Indoor Fireplace',\n",
       " 'Pets live on this property',\n",
       " 'Suitable for Events',\n",
       " 'Pets Allowed',\n",
       " 'Smoke Detector',\n",
       " 'Laptop Friendly Workspace',\n",
       " 'Washer / Dryer',\n",
       " 'Doorman',\n",
       " 'Breakfast',\n",
       " 'Hot Tub',\n",
       " 'Kitchen',\n",
       " 'Fire Extinguisher',\n",
       " 'Other pets',\n",
       " 'Gym',\n",
       " 'Pool',\n",
       " 'Dryer',\n",
       " 'Cats',\n",
       " 'Washer',\n",
       " 'Internet',\n",
       " 'Cable TV',\n",
       " 'Essentials',\n",
       " 'Wireless Internet',\n",
       " 'Air Conditioning',\n",
       " 'Smoking Allowed',\n",
       " 'Family/Kid Friendly',\n",
       " 'Carbon Monoxide Detector',\n",
       " 'Iron',\n",
       " 'TV',\n",
       " 'Free Parking on Street',\n",
       " 'Lock on Bedroom Door',\n",
       " 'Hair Dryer',\n",
       " 'Dogs',\n",
       " 'Shampoo',\n",
       " 'Wheelchair Accessible',\n",
       " 'Paid Parking Off Premises',\n",
       " 'Free Parking on Premises']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.to_pickle('data/listing_cleaned.pkl')\n",
    "amenities = list(set([item for item_list in listings.amenities for item in item_list]) \\\n",
    "         - set(['translation missing enhosting_amenity_49','translation missing enhosting_amenity_50','']))\n",
    "amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_remove = ['host_id',\n",
    "                  'zipcode',\n",
    "                  'neighbourhood_cleansed',\n",
    "                  'latitude',\n",
    "                  'longitude', 'amenities', 'first_review', 'room_type','property_type', 'listed_price', 'Carbon Monoxide Detector', 'Entire home/apt','Apartment']\n",
    "del analysis_data_x['q1_revenue']\n",
    "del analysis_data_x['q2_revenue']\n",
    "del analysis_data_x['q3_revenue']\n",
    "del analysis_data_x['q4_revenue']\n",
    "\n",
    "del analysis_data_x['review_scores_rating']\n",
    "del analysis_data_x['review_scores_rating_zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accommodates',\n",
       " 'amenities',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'calculated_host_listings_count',\n",
       " 'cancellation_policy',\n",
       " 'cleaning_fee',\n",
       " 'first_review',\n",
       " 'host_id',\n",
       " 'instant_bookable',\n",
       " 'latitude',\n",
       " 'listed_price',\n",
       " 'longitude',\n",
       " 'minimum_nights',\n",
       " 'neighbourhood_cleansed',\n",
       " 'number_of_reviews',\n",
       " 'property_type',\n",
       " 'q1_occupancy_rate',\n",
       " 'q1_revenue',\n",
       " 'q2_occupancy_rate',\n",
       " 'q2_revenue',\n",
       " 'q3_occupancy_rate',\n",
       " 'q3_revenue',\n",
       " 'q4_occupancy_rate',\n",
       " 'q4_revenue',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_value',\n",
       " 'reviews_per_month',\n",
       " 'room_type',\n",
       " 'zipcode'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(listings.columns)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
