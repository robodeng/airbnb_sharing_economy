{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enable matplotlib to display in jupyter notebook & import it\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from geopy.geocoders import Nominatim #used in filling missing zipcodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Listings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#listings.csv READING\n",
    "\n",
    "LISTINGS = 'data/listings.csv'\n",
    "\n",
    "#Choose which columns from the csv to read in.\n",
    "listings_cols = ['id',\n",
    "                'host_id',\n",
    "                'neighbourhood_cleansed',\n",
    "                'zipcode',\n",
    "                'latitude',\n",
    "                'longitude',\n",
    "                'property_type',\n",
    "                'room_type',\n",
    "                'accommodates',\n",
    "                'bathrooms',\n",
    "                'amenities',\n",
    "                'price',\n",
    "                'cleaning_fee',\n",
    "                'number_of_reviews',\n",
    "                'first_review',\n",
    "                'review_scores_rating',\n",
    "                'review_scores_accuracy',\n",
    "                'review_scores_cleanliness',\n",
    "                'review_scores_checkin',\n",
    "                'review_scores_communication',\n",
    "                'review_scores_location',\n",
    "                'review_scores_value',\n",
    "                'calculated_host_listings_count',\n",
    "                'reviews_per_month'] \n",
    "\n",
    "#Read in data from the csv\n",
    "listings = pd.read_csv(LISTINGS, usecols=listings_cols)\n",
    "\n",
    "#Rename any Columns as needed\n",
    "rename_dict = {'id':'listing_id',\n",
    "              'price':'listed_price'}\n",
    "listings.rename(columns = rename_dict, inplace=True)\n",
    "\n",
    "#use listing_id as index\n",
    "listings.set_index('listing_id', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#############################\n",
    "#         Cleaning          #\n",
    "#############################\n",
    "\n",
    "# 'zipcode' ##########\n",
    "#Paste this in to zipcode section of cleaning\n",
    "def latLonToZip(lat, lon):\n",
    "    '''Take in a latitude and longitude and return the zipcode for that location'''\n",
    "    geolocator = Nominatim()\n",
    "    try:\n",
    "        location = geolocator.reverse(str(lat)+','+str(lon))\n",
    "        z = re.compile('(\\s)([0-9]{5})(,\\sUnited)')\n",
    "        return z.findall(location[0])[0][1]\n",
    "    except:\n",
    "        print(str(lat)+','+str(lon),'-----',location)\n",
    "        return np.nan\n",
    "    \n",
    "    print(str(lat)+','+str(lon),'-----',location)\n",
    "    return np.nan\n",
    "#Find all missing zippcodes : missing_zipcodes\n",
    "missing_zipcodes = listings[listings.zipcode.isnull()].copy()\n",
    "\n",
    "#update rows that are missing zipcodes using latLonToZip to fill missin\n",
    "listings.zipcode.update(missing_zipcodes.apply(lambda x: latLonToZip(x['latitude'], x['longitude']), axis=1))\n",
    "\n",
    "#Remove 'zip+4' part of any zipcode \n",
    "listings.zipcode = listings.zipcode.apply(lambda x: x[:5])\n",
    "\n",
    "# 'price' --> 'listed_price' ##########\n",
    "listings.listed_price = listings.listed_price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "# 'cleaning_fee' ##########\n",
    "listings.cleaning_fee = listings.cleaning_fee.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "# 'first_review' ##########\n",
    "listings.first_review = pd.to_datetime(listings.first_review)\n",
    "\n",
    "# 'amenities' ##########\n",
    "listings.amenities = listings.amenities.replace('[^\\w,\\s/]+','',regex=True).apply(lambda x: x.split(','))\n",
    "\n",
    "\n",
    "\n",
    "#Save to Pickle because it preserves the index and types###################\n",
    "listings.to_pickle('data/listings_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Calendar.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calendar.csv READING\n",
    "\n",
    "CALENDAR = 'data/calendar.csv'\n",
    "\n",
    "#Read in all columns from calendar.csv : listing_id, date, available, price\n",
    "calendar = pd.read_csv(CALENDAR)\n",
    "\n",
    "\n",
    "#############################\n",
    "#         Cleaning          #\n",
    "#############################\n",
    "\n",
    "# 'date' ##########\n",
    "calendar.date = pd.to_datetime(calendar.date)\n",
    "\n",
    "# 'available' ##########\n",
    "calendar.available.replace({'f':False,'t':True}, inplace=True)\n",
    "\n",
    "# 'price' ##########\n",
    "calendar.price = calendar.price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "#############################\n",
    "#         Augmenting        #\n",
    "#############################\n",
    "\n",
    "#create column to represent the day of the week for each date\n",
    "calendar['day_of_week'] = calendar.date.dt.dayofweek\n",
    "\n",
    "#Fill in missing price values for each listing using mean value for day of week from that listing\n",
    "calendar.price.fillna(calendar.groupby(['listing_id','day_of_week'])['price'].transform(\"mean\"), inplace=True)\n",
    "\n",
    "#create column for revenue generate by property (all prices for occupied days are modeled from mean)\n",
    "calendar['day_revenue'] = np.where(calendar.available, 0.0, calendar.price)\n",
    "\n",
    "#Save to Pickle because it preserves the index and types\n",
    "calendar.to_pickle('data/calendar_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Using Calendar to Augment Listings DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listings = pd.read_pickle('data/listings_cleaned.pkl')\n",
    "calendar = pd.read_pickle('data/calendar_cleaned.pkl')\n",
    "\n",
    "#Create a list of calendars seperated into 4 quarters\n",
    "quarter_dates = ['2016-09-06','2016-12-06','2017-03-06','2017-06-06','2017-09-06']\n",
    "q_cal = [calendar[calendar.date.isin(pd.date_range(quarter_dates[n], quarter_dates[n+1]))] for n in range(4)]\n",
    "\n",
    "#Revnue Per Quarter\n",
    "for n,q in enumerate(q_cal):\n",
    "    listings = listings.join(q_cal[n].groupby('listing_id').day_revenue.sum()).rename(columns={'day_revenue':'q'+str(n+1)+'_revenue'})\n",
    "\n",
    "#Occupancy Per Quarter\n",
    "for n,q in enumerate(q_cal):\n",
    "    q_len = len(pd.date_range(quarter_dates[n], quarter_dates[n+1]))\n",
    "    listings = listings.join((q_len - q_cal[n].groupby('listing_id').available.sum())/q_len).rename(columns={'available':'q'+str(n+1)+'_occupancy_rate'})\n",
    "\n",
    "listings.to_pickle('data/listing_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amenities = list(set([item for item_list in listings.amenities for item in item_list]))\n",
    "amenities.remove('translation missing enhosting_amenity_49')\n",
    "amenities.remove('')\n",
    "\n",
    "amn_frame = pd.DataFrame(index = listings.index)\n",
    "\n",
    "for amn in amenities:\n",
    "    amn_frame = amn_frame.join(listings.amenities.apply(lambda amns: amn in amns)).rename(columns={'amenities':amn})\n",
    "\n",
    "analysis_table = amn_frame.copy()\n",
    "listings['analysis_table'] = listings.index\n",
    "listings['analysis_table'] = pd.DataFrame(listings.analysis_table.map(lambda x: amn_frame.loc[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Hosts by Listings Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import os\n",
    "from matplotlib import colors\n",
    "\n",
    "#map with our data in center\n",
    "thisMap = folium.Map([42.321145, -71.057083], zoom_start=12, tiles=\"Cartodb Positron\")\n",
    "\n",
    "\n",
    "#create a color dictionary for with custom buckets\n",
    "buckets = [(1,1+1),(2,4+1),(5,10+1),(11,49+1),(50,136+1)]\n",
    "color_names = ['blue','whitesmoke','silver','grey','red']\n",
    "color_dict = {}\n",
    "for n in range(len(buckets)):\n",
    "    for m in range(buckets[n][0],buckets[n][1]):\n",
    "        color_dict[m] = colors.to_hex(color_names[n])\n",
    "\n",
    "\n",
    "\n",
    "for n in listings.index:\n",
    "    alist = listings.loc[n]\n",
    "    plot_val = alist.calculated_host_listings_count\n",
    "    popup_text = str(plot_val)\n",
    "    folium.CircleMarker(location=[alist.latitude, alist.longitude], radius=1,\n",
    "    popup=popup_text, color=color_dict[plot_val],\n",
    "    fill_color=color_dict[plot_val]).add_to(thisMap)\n",
    "\n",
    "thisMap.save(os.path.join('Listings_Colored_by_Host_Listing_Count.html'))\n",
    "\n",
    "thisMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      1768\n",
       "2       233\n",
       "3        71\n",
       "4        37\n",
       "5        17\n",
       "6        14\n",
       "7        10\n",
       "8         3\n",
       "9         2\n",
       "10        5\n",
       "11        3\n",
       "12        1\n",
       "13        1\n",
       "14        1\n",
       "15        2\n",
       "17        1\n",
       "19        1\n",
       "20        2\n",
       "24        3\n",
       "25        1\n",
       "50        1\n",
       "58        1\n",
       "61        1\n",
       "79        1\n",
       "136       1\n",
       "Name: calculated_host_listings_count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_counts = listings.groupby('host_id').calculated_host_listings_count.mean().value_counts().sort_index()\n",
    "host_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      1768\n",
       "2       466\n",
       "3       213\n",
       "4       148\n",
       "5        85\n",
       "6        84\n",
       "7        70\n",
       "8        24\n",
       "9        18\n",
       "10       50\n",
       "11       33\n",
       "12       12\n",
       "13       13\n",
       "14       14\n",
       "15       30\n",
       "17       17\n",
       "19       19\n",
       "20       40\n",
       "24       72\n",
       "25       25\n",
       "50       50\n",
       "58       58\n",
       "61       61\n",
       "79       79\n",
       "136     136\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(host_counts.index * host_counts, index = host_counts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 in range(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#f5f5f5'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#f5f5f5'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import colors\n",
    "colors.to_hex('whitesmoke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '#0000ff',\n",
       " 2: '#f5f5f5',\n",
       " 3: '#f5f5f5',\n",
       " 4: '#f5f5f5',\n",
       " 5: '#c0c0c0',\n",
       " 6: '#c0c0c0',\n",
       " 7: '#c0c0c0',\n",
       " 8: '#c0c0c0',\n",
       " 9: '#c0c0c0',\n",
       " 10: '#c0c0c0',\n",
       " 11: '#808080',\n",
       " 12: '#808080',\n",
       " 13: '#808080',\n",
       " 14: '#808080',\n",
       " 15: '#808080',\n",
       " 16: '#808080',\n",
       " 17: '#808080',\n",
       " 18: '#808080',\n",
       " 19: '#808080',\n",
       " 20: '#808080',\n",
       " 21: '#808080',\n",
       " 22: '#808080',\n",
       " 23: '#808080',\n",
       " 24: '#808080',\n",
       " 25: '#808080',\n",
       " 26: '#808080',\n",
       " 27: '#808080',\n",
       " 28: '#808080',\n",
       " 29: '#808080',\n",
       " 30: '#808080',\n",
       " 31: '#808080',\n",
       " 32: '#808080',\n",
       " 33: '#808080',\n",
       " 34: '#808080',\n",
       " 35: '#808080',\n",
       " 36: '#808080',\n",
       " 37: '#808080',\n",
       " 38: '#808080',\n",
       " 39: '#808080',\n",
       " 40: '#808080',\n",
       " 41: '#808080',\n",
       " 42: '#808080',\n",
       " 43: '#808080',\n",
       " 44: '#808080',\n",
       " 45: '#808080',\n",
       " 46: '#808080',\n",
       " 47: '#808080',\n",
       " 48: '#808080',\n",
       " 49: '#808080',\n",
       " 50: '#ff0000',\n",
       " 51: '#ff0000',\n",
       " 52: '#ff0000',\n",
       " 53: '#ff0000',\n",
       " 54: '#ff0000',\n",
       " 55: '#ff0000',\n",
       " 56: '#ff0000',\n",
       " 57: '#ff0000',\n",
       " 58: '#ff0000',\n",
       " 59: '#ff0000',\n",
       " 60: '#ff0000',\n",
       " 61: '#ff0000',\n",
       " 62: '#ff0000',\n",
       " 63: '#ff0000',\n",
       " 64: '#ff0000',\n",
       " 65: '#ff0000',\n",
       " 66: '#ff0000',\n",
       " 67: '#ff0000',\n",
       " 68: '#ff0000',\n",
       " 69: '#ff0000',\n",
       " 70: '#ff0000',\n",
       " 71: '#ff0000',\n",
       " 72: '#ff0000',\n",
       " 73: '#ff0000',\n",
       " 74: '#ff0000',\n",
       " 75: '#ff0000',\n",
       " 76: '#ff0000',\n",
       " 77: '#ff0000',\n",
       " 78: '#ff0000',\n",
       " 79: '#ff0000',\n",
       " 80: '#ff0000',\n",
       " 81: '#ff0000',\n",
       " 82: '#ff0000',\n",
       " 83: '#ff0000',\n",
       " 84: '#ff0000',\n",
       " 85: '#ff0000',\n",
       " 86: '#ff0000',\n",
       " 87: '#ff0000',\n",
       " 88: '#ff0000',\n",
       " 89: '#ff0000',\n",
       " 90: '#ff0000',\n",
       " 91: '#ff0000',\n",
       " 92: '#ff0000',\n",
       " 93: '#ff0000',\n",
       " 94: '#ff0000',\n",
       " 95: '#ff0000',\n",
       " 96: '#ff0000',\n",
       " 97: '#ff0000',\n",
       " 98: '#ff0000',\n",
       " 99: '#ff0000',\n",
       " 100: '#ff0000',\n",
       " 101: '#ff0000',\n",
       " 102: '#ff0000',\n",
       " 103: '#ff0000',\n",
       " 104: '#ff0000',\n",
       " 105: '#ff0000',\n",
       " 106: '#ff0000',\n",
       " 107: '#ff0000',\n",
       " 108: '#ff0000',\n",
       " 109: '#ff0000',\n",
       " 110: '#ff0000',\n",
       " 111: '#ff0000',\n",
       " 112: '#ff0000',\n",
       " 113: '#ff0000',\n",
       " 114: '#ff0000',\n",
       " 115: '#ff0000',\n",
       " 116: '#ff0000',\n",
       " 117: '#ff0000',\n",
       " 118: '#ff0000',\n",
       " 119: '#ff0000',\n",
       " 120: '#ff0000',\n",
       " 121: '#ff0000',\n",
       " 122: '#ff0000',\n",
       " 123: '#ff0000',\n",
       " 124: '#ff0000',\n",
       " 125: '#ff0000',\n",
       " 126: '#ff0000',\n",
       " 127: '#ff0000',\n",
       " 128: '#ff0000',\n",
       " 129: '#ff0000',\n",
       " 130: '#ff0000',\n",
       " 131: '#ff0000',\n",
       " 132: '#ff0000',\n",
       " 133: '#ff0000',\n",
       " 134: '#ff0000',\n",
       " 135: '#ff0000',\n",
       " 136: '#ff0000'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/collinreinking/Google_Drive/Data_Science/MIDS/W18_Python/boston-airbnb-open-data\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
