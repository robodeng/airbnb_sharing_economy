{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enable matplotlib to display in jupyter notebook & import it\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read Files\n",
    "#\"originals\" should never be modified.  They exist to check work.  They should be deleted in our final work\n",
    "listings_original = pd.read_csv('data/listings.csv')\n",
    "calendar_oiginal = pd.read_csv('data/calendar.csv')\n",
    "reviews_original = pd.read_csv('data/reviews.csv')\n",
    "\n",
    "listings = listings_original.copy()\n",
    "calendar = calendar_oiginal.copy()\n",
    "reviews = reviews_original.copy()\n",
    "\n",
    "# #Final version should just have the code below\n",
    "# listings = pd.read_csv('data/listings.csv')\n",
    "# calendar = pd.read_csv('data/calendar.csv')\n",
    "# reviews = pd.read_csv('data/reviews.csv')\n",
    "\n",
    "#3585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for testing\n",
    "listings = listings_original.copy()\n",
    "\n",
    "#listings.columns[(listings.isnull().sum()==3585)]\n",
    "#returns these (empty variables)\n",
    "#Index(['neighbourhood_group_cleansed', 'has_availability', 'license','jurisdiction_names'],\n",
    "      \n",
    "      \n",
    "# Description:  \n",
    "# Original shape = (3585, 95)\n",
    "\n",
    "# id\n",
    "# Type: Float\n",
    "# What: The listing id is a unique id # for each property being listed on airBnB\n",
    "# Cleaning: change to string, there is no reason to treat these as numbers, SET AS INDEX\n",
    "listings.id = listings.id.astype(str)\n",
    "#listings.index = set_index('id', inplace=True) #this also sets index but doesn't leave me with id as a column\n",
    "listings.index = listings.id.copy()\n",
    "\n",
    "# listing_url\n",
    "# Type: String\n",
    "# What: Url in for the listing in the format: \"https://www.airbnb.com/rooms/\" + listing.id\n",
    "# Cleaning: leave in for easy access to listings while exploring data\n",
    "\n",
    "# scrape_id\n",
    "# Type: int\n",
    "# What: Identify which webscrape the data came from, all of Boston came from the same scrape: 20160906204935\n",
    "#Cleaning: Delete.  Not relevant to our analysis\n",
    "del(listings['scrape_id'])\n",
    "\n",
    "# last_scraped\n",
    "# Type: str\n",
    "# What: The date that our data was scraped, it is the same for all of Boston entries: 2016-09-07\n",
    "# Cleaning : Convert to date\n",
    "listings.last_scraped = pd.to_datetime(listings.last_scraped)\n",
    "\n",
    "# name\n",
    "# Type: str\n",
    "# What: This text is the \"title\" of any listing.  In a search result it would \n",
    "#       be the text that users see as the first description of a listing.  It\n",
    "#       is also the title of the page for a listing in browser history. etc.\n",
    "# Cleaning:  None\n",
    "# Uses: keyword analysis\n",
    "pass\n",
    "\n",
    "# summary\n",
    "# Type: str or NaN\n",
    "# What: Prose that is displayed on listing webpage for \"About this listing\".\n",
    "# Cleaning: Fill NaN with \"none\" so that all types match\n",
    "# Uses: Keyword analysis\n",
    "pass\n",
    "len(listings.summary.unique()) #=3114\n",
    "listings.summary = listings.summary.fillna('none')\n",
    "listings.summary[listings.summary == 'none'].count() #=143\n",
    "listings.summary.value_counts().index[1] #most common summary other than \"none\"\n",
    "listings[listings.summary == listings.summary.value_counts().index[1]]\n",
    "#more exploration of duplicates needed\n",
    "\n",
    "\n",
    "# space\n",
    "# Type: str or NaN\n",
    "# What: [OPTIONAL] Prose to describe the inside space of a listing\n",
    "# Cleaning: Fill NaN with \"none\" so that all types match\n",
    "\n",
    "listings.space.isnull().any()\n",
    "len(listings.space.unique()) #=2269\n",
    "listings.space = listings.space.fillna('none')\n",
    "listings.space[listings.space == 'none'].count() #=1057\n",
    "listings.space.value_counts()\n",
    "#more exploration of duplicates needed\n",
    "\n",
    "# description\n",
    "# Type: str\n",
    "# What: Prose that contains the first 1000 characters of the merging of other descriptive prose:\n",
    "#     summary\n",
    "#     space\n",
    "#     experiences_offered\n",
    "#     neighborhood_overview\n",
    "#     notes\n",
    "#     transit\n",
    "#     access\n",
    "#     interaction\n",
    "#     house_rules\n",
    "# Cleaning: Delete.  the fact that it only gives us the first 1000 characters makes it unuseful.\n",
    "del(listings['description'])\n",
    "\n",
    "pass\n",
    "\n",
    "# experiences_offered\n",
    "# Type: str\n",
    "# What: 'none' for every entry\n",
    "# Cleaning: Delete\n",
    "del(listings['experiences_offered'])\n",
    "\n",
    "# neighborhood_overview\n",
    "# Type: str or NaN\n",
    "# What: [OPTIONAL] description by host of the neighborhood \n",
    "# Cleaning: Fill NaN with \"none\" so that all types match\n",
    "listings.neighborhood_overview.isnull().sum() #=1415\n",
    "len(listings.neighborhood_overview.unique()) #=1729\n",
    "listings.neighborhood_overview = listings.neighborhood_overview.fillna('none')\n",
    "#more exploration of duplicates needed\n",
    "\n",
    "# notes\n",
    "# Type: str or NaN\n",
    "# What: [OPTIONAL] under \"Other things to note\" in the description on webpage\n",
    "# Cleaning: Fill NaN with \"none\" so that all types match\n",
    "listings.notes.isnull().sum() #=1975\n",
    "listings.notes.fillna('none')\n",
    "len(listings.notes.unique()) #=1270\n",
    "#more exploration of duplicates needed\n",
    "\n",
    "\n",
    "# transit\n",
    "# Type: str or NaN\n",
    "# What: [OPTIONAL] under \"Getting around\" in the description on webpage\n",
    "# Cleaning: Fill NaN with \"none\" so that all types match\n",
    "listings.transit.isnull().sum()\n",
    "listings.transit.fillna('none')\n",
    "len(listings.transit.unique())\n",
    "#more exploration of duplicates needed\n",
    "\n",
    "\n",
    "# access\n",
    "# Type: str or NaN\n",
    "# What: [OPTIONAL] under \"Guest access\" in the description on webpage\n",
    "# Cleaning: Fill NaN with \"none\" so that all types match\n",
    "listings.access.isnull().sum() #=1489\n",
    "listings.access.fillna('none') \n",
    "len(listings.access.unique()) #=1763\n",
    "#more exploration of duplicates needed\n",
    "\n",
    "\n",
    "# interaction\n",
    "# Type: str or NaN\n",
    "# What: [OPTIONAL] under \"Interaction with guests\" in the description on webpage\n",
    "# Cleaning: Fill NaN with \"none\" so that all types match\n",
    "listings.interaction.isnull().sum() #=1554\n",
    "listings.interaction.fillna('none') \n",
    "len(listings.interaction.unique()) #=1618\n",
    "#more exploration of duplicates needed\n",
    "\n",
    "\n",
    "# house_rules\n",
    "# Type: str or NaN\n",
    "# What: [OPTIONAL] under \"Interaction with guests\" in the description on webpage\n",
    "# Cleaning: Fill NaN with \"none\" so that all types match\n",
    "listings.house_rules.isnull().sum() #=1192\n",
    "listings.house_rules.fillna('none') \n",
    "len(listings.house_rules.unique()) #=1929\n",
    "\n",
    "\n",
    "\n",
    "# thumbnail_url\n",
    "# medium_url\n",
    "# picture_url\n",
    "# xl_picture_url\n",
    "# Type: str or NaN\n",
    "# What: URL to different image resourses\n",
    "# Cleaning: Delete\n",
    "del(listings['thumbnail_url'])\n",
    "del(listings['medium_url'])\n",
    "del(listings['picture_url'])\n",
    "del(listings['xl_picture_url'])\n",
    "\n",
    "# host_id\n",
    "# Type: int\n",
    "# What: The listing id is a unique id # for each host on airbnb\n",
    "# Cleaning: change to string, there is no reason to treat these as numbers\n",
    "listings.host_id = listings.host_id.astype(str)\n",
    "\n",
    "# host_url\n",
    "# Cleaning: Delete\n",
    "del(listings['host_url'])\n",
    "\n",
    "\n",
    "# host_name\n",
    "# Type: str\n",
    "# What: Host first name only\n",
    "# Cleaning: append the user id to each host_Name to distinguish between people with the same name\n",
    "listings['host_name'] = listings['host_name'] + ' ' + listings['host_id']\n",
    "#listings.host_name.value_counts()\n",
    "\n",
    "# host_since\n",
    "# Type: str\n",
    "# What:\n",
    "# Cleaning: convert to date\n",
    "listings.host_since = pd.to_datetime(listings.host_since)\n",
    "\n",
    "# host_location\n",
    "# Type: str\n",
    "# What: Location that the host lives in\n",
    "# Cleaning: need to parse out city, state, country if they are there ###############\n",
    "listings.host_location[1]\n",
    "\n",
    "\n",
    "# host_about\n",
    "\n",
    "# host_response_time\n",
    "\n",
    "# host_response_rate\n",
    "\n",
    "# host_acceptance_rate\n",
    "\n",
    "# host_is_superhost\n",
    "\n",
    "# host_thumbnail_url\n",
    "# Cleaning: Delete\n",
    "del(listings['host_thumbnail_url'])\n",
    "\n",
    "# host_picture_url\n",
    "# Cleaning: Delete\n",
    "del(listings['host_picture_url'])\n",
    "\n",
    "# host_neighbourhood\n",
    "\n",
    "# host_listings_count\n",
    "# Type: int\n",
    "# What: The number of listings that the host has ACROSS ALL OF AIRBNB\n",
    "# Related: If you want the number of listings that they have in this set, use calculated_host_listings_count\n",
    "\n",
    "# host_total_listings_count\n",
    "# Cleaning: Delete\n",
    "(listings['host_total_listings_count'] == listings['host_listings_count']).all() #true\n",
    "del(listings['host_total_listings_count'])\n",
    "\n",
    "# host_verifications\n",
    "\n",
    "# host_has_profile_pic\n",
    "# Cleaning: Delete, only 7 don't have a pic, also not relevant to our work\n",
    "listings.host_has_profile_pic[listings.host_has_profile_pic == 'f'] #there were 7 listings\n",
    "del(listings['host_has_profile_pic'])\n",
    "\n",
    "# host_identity_verified\n",
    "\n",
    "\n",
    "# street\n",
    "\n",
    "# neighbourhood\n",
    "# neighbourhood_cleansed\n",
    "n = listings[['neighbourhood','neighbourhood_cleansed']]\n",
    "n = n[(n['neighbourhood'] != n['neighbourhood_cleansed'])]\n",
    "n[(n['neighbourhood'] == n['neighbourhood'])]\n",
    "########it is strange to me that these don't match up.  there's something here we might want to understand\n",
    "\n",
    "# neighbourhood_group_cleansed\n",
    "# Cleaning: Delete, empty variable (all null)\n",
    "del listings['neighbourhood_group_cleansed']\n",
    "\n",
    "\n",
    "# city\n",
    "# state\n",
    "# zipcode\n",
    "\n",
    "\n",
    "# market\n",
    "# Cleaning: Delete\n",
    "listings.market[listings.market != 'Boston'] ######the results from this are very odd\n",
    "del listings['market']\n",
    "\n",
    "\n",
    "# smart_location\n",
    "# Cleaning: Delete, redundant with city\n",
    "listings[['smart_location','city']] #there are only two listings that don't appear to match, 14767573 and 14743129\n",
    "del listings['city']\n",
    "\n",
    "\n",
    "# country_code\n",
    "# Cleaning: Delete\n",
    "(listings.country_code == listings.country_code[0]).all() #=True: 'US'\n",
    "del listings['country_code']\n",
    "\n",
    "# country\n",
    "(listings.country == listings.country[0]).all() #=True: 'United States'\n",
    "del listings['country']\n",
    "\n",
    "# latitude\n",
    "# longitude\n",
    "# is_location_exact\n",
    "# property_type\n",
    "# room_type\n",
    "# accommodates\n",
    "# bathrooms\n",
    "# bedrooms\n",
    "# beds\n",
    "# bed_type\n",
    "# amenities\n",
    "\n",
    "# square_feet\n",
    "# Cleaning:  We may want to consider deleting this variable, only 56 entries have data\n",
    "listings.square_feet.isnull().sum() #=3529\n",
    "listings.square_feet = listings.square_feet.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "# price\n",
    "#this regex \"replaces\" anything that is not a digit or a decimal with the empty string\n",
    "#effectively removing anything that's not part of the number\n",
    "listings.price = listings.price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "\n",
    "# weekly_price\n",
    "listings.weekly_price = listings.weekly_price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "# monthly_price\n",
    "listings.monthly_price = listings.monthly_price.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "# security_deposit\n",
    "listings.security_deposit = listings.security_deposit.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "# cleaning_fee\n",
    "listings.cleaning_fee = listings.cleaning_fee.replace('[^0-9.]+','',regex=True).astype(float)\n",
    "\n",
    "# guests_included\n",
    "# extra_people\n",
    "# minimum_nights\n",
    "# maximum_nights\n",
    "# calendar_updated\n",
    "\n",
    "# has_availability\n",
    "# Cleaning: Delete, empty variable (all null)\n",
    "del listings['has_availability']\n",
    "\n",
    "\n",
    "\n",
    "# availability_30\n",
    "# availability_60\n",
    "# availability_90\n",
    "# availability_365\n",
    "# calendar_last_scraped\n",
    "# number_of_reviews\n",
    "# first_review\n",
    "# last_review\n",
    "# review_scores_rating\n",
    "# review_scores_accuracy\n",
    "# review_scores_cleanliness\n",
    "# review_scores_checkin\n",
    "# review_scores_communication\n",
    "# review_scores_location\n",
    "# review_scores_value\n",
    "# requires_license\n",
    "\n",
    "# license\n",
    "# Cleaning: Delete, empty variable (all null)\n",
    "del listings['license']\n",
    "\n",
    "# jurisdiction_names\n",
    "# Cleaning: Delete, empty variable (all null)\n",
    "del listings['jurisdiction_names']\n",
    "\n",
    "# instant_bookable\n",
    "# cancellation_policy\n",
    "# require_guest_profile_picture\n",
    "# require_guest_phone_verification\n",
    "\n",
    "\n",
    "# calculated_host_listings_count\n",
    "# Type: int\n",
    "# What: The number of listings that the host has THIS data set\n",
    "# Related: If you want the number of th listings that the host has across ALL of airbnb\n",
    "#          use host_listings_count\n",
    "#listings.calculated_host_listings_count == listings.host_listings_count # not all true\n",
    "#listings[['host_id','calculated_host_listings_count','host_listings_count']][listings.calculated_host_listings_count != listings.host_listings_count]\n",
    "\n",
    "\n",
    "# reviews_per_month\n",
    "\n",
    "\n",
    "\n",
    "#####dead end code to fix zipcodes\n",
    "listings[listings.zipcode.isnull()].neighbourhood_cleansed\n",
    "nczdict = {}\n",
    "for n in listings.neighbourhood_cleansed.unique():\n",
    "    nczdict[n] = listings[listings.neighbourhood_cleansed == n].zipcode.value_counts().idxmax()\n",
    "\n",
    "#print(nczdict)\n",
    "\n",
    "nzdict = {}\n",
    "for n in listings.neighbourhood.unique():\n",
    "    if type(n) == str:\n",
    "        nzdict[n] = listings[listings.neighbourhood == n].zipcode.value_counts().idxmax()\n",
    "\n",
    "#print(nzdict)\n",
    "\n",
    "\n",
    "#######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.34128360140666,-71.08567288767645\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# This code is a work in progress to fil in missing zip codes\n",
    "#\n",
    "####\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def latlonToZip(lat, lon):\n",
    "    geolocator = Nominatim()\n",
    "    try:\n",
    "        location = geolocator.reverse(str(lat)+','+str(lon))\n",
    "        z = re.compile('(,\\s)([0-9]{5})(,\\sUnited)')\n",
    "        #print(z.findall(location[0])[0][1])\n",
    "        return z.findall(location[0])[0][1]\n",
    "    except:\n",
    "        print(str(lat)+','+str(lon))\n",
    "        return np.nan\n",
    "    \n",
    "    print(str(lat)+','+str(lon))\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "#lat = listings[listings.zipcode.isnull()][['latitude','longitude']].latitude[0]\n",
    "#lon = listings[listings.zipcode.isnull()][['latitude','longitude']].longitude[0]\n",
    "\n",
    "temp = listings[listings.zipcode.isnull()].copy()\n",
    "temp.shape\n",
    "#latlonToZip(lat,lon)\n",
    "temp['new_zip'] = temp.apply(lambda x: latlonToZip(x['latitude'], x['longitude']), axis=1)\n",
    "\n",
    "listings['new_zip'] = listings['zipcode'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>new_zip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10084216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11229070</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141888</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12026868</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12646288</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789527</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12971157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13073078</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13077603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13098572</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13391640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13397201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13512551</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13577929</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13642024</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13713713</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13729738</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13926201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14094279</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14110129</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14336348</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14344516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14600925</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14604429</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14707780</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14808548</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14823430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14918869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043541</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538536</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4350898</th>\n",
       "      <td>NaN</td>\n",
       "      <td>01125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274342</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751520</th>\n",
       "      <td>NaN</td>\n",
       "      <td>02128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         zipcode new_zip\n",
       "id                      \n",
       "10084216     NaN   02116\n",
       "11229070     NaN   02113\n",
       "1141888      NaN   02115\n",
       "12026868     NaN   02134\n",
       "12646288     NaN   02128\n",
       "12789527     NaN   02130\n",
       "12971157     NaN   02128\n",
       "13073078     NaN     NaN\n",
       "13077603     NaN   02119\n",
       "13098572     NaN   02121\n",
       "13391640     NaN   02116\n",
       "13397201     NaN   02115\n",
       "13512551     NaN   02130\n",
       "13577929     NaN   02135\n",
       "13642024     NaN   02127\n",
       "13713713     NaN   02210\n",
       "13729738     NaN   02116\n",
       "13926201     NaN   02102\n",
       "14094279     NaN   02118\n",
       "14110129     NaN   02116\n",
       "14336348     NaN   02120\n",
       "14340601     NaN   02134\n",
       "14344516     NaN   02128\n",
       "1436513      NaN   02131\n",
       "14600925     NaN   02122\n",
       "14604429     NaN   02446\n",
       "14707780     NaN   02135\n",
       "14808548     NaN   02109\n",
       "14823430     NaN   02446\n",
       "14918869     NaN   02118\n",
       "2043541      NaN   02109\n",
       "2538536      NaN   02130\n",
       "4350898      NaN   01125\n",
       "4435883      NaN   02210\n",
       "639101       NaN   02118\n",
       "639111       NaN   02118\n",
       "7274342      NaN   02118\n",
       "9751520      NaN   02128"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = listings.combine_first(temp)\n",
    "final[['zipcode','new_zip']][final.zipcode != final.new_zip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values, which use np.object_ dtype in pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-9b52f2217992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'listing_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'listing_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'$'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/collinreinking/anaconda3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2666\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   2667\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 2668\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/collinreinking/anaconda3/lib/python3.5/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m# this ensures that Series.str.<method> is well defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccessor_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/collinreinking/anaconda3/lib/python3.5/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_make_str_accessor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1816\u001b[0m             \u001b[0;31m# (instead of test for object dtype), but that isn't practical for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m             \u001b[0;31m# performance reasons until we have a str dtype (GH 9343)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m             raise AttributeError(\"Can only use .str accessor with string \"\n\u001b[0m\u001b[1;32m   1819\u001b[0m                                  \u001b[0;34m\"values, which use np.object_ dtype in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m                                  \"pandas\")\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values, which use np.object_ dtype in pandas"
     ]
    }
   ],
   "source": [
    "#coerce appropriate fields to datetime\n",
    "listings['host_since'] = pd.to_datetime(listings['host_since'])\n",
    "\n",
    "listings['price'] = listings['price'].str.replace('$','')\n",
    "listings['price'] = listings['price'].str.replace(',','')\n",
    "listings['price'] = listings['price'].astype(float)\n",
    "\n",
    "listings['zipcode'] = listings['zipcode'].str.replace('-','')\n",
    "listings['zipcode'] = listings['zipcode'].str.replace(' ', '')\n",
    "listings['mainzip'] = pd.Series([str(z)[:5] for z in listings['zipcode'].fillna('00000')]) ##THIS IS NOT WORKING AS I WANT IT TO; AIMING TO GRAB FIRST FIVE NUMBERS TO CREATE NEW FILE\n",
    "\n",
    "#CLEANING FEE\n",
    "\n",
    "listings['cleaning_fee'] = listings['cleaning_fee'].str.replace('$','')\n",
    "listings['cleaning_fee'] = listings['cleaning_fee'].str.replace(',','')\n",
    "\n",
    "listings['cleaning_fee'] = listings['cleaning_fee'].astype(float)\n",
    "\n",
    "#CALENDAR LAST SCRAPED\n",
    "listings['calendar_last_scraped'] = pd.to_datetime(listings['calendar_last_scraped'])\n",
    "\n",
    "\n",
    "##################################      REVIEWS       #####################################################\n",
    "reviews['date'] = pd.to_datetime(reviews['date'])\n",
    "\n",
    "##################################      CALENDAR       #####################################################\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar['listing_id'] = calendar['listing_id'].astype('category')\n",
    "calendar['price'] = calendar['price'].str.replace('$','')\n",
    "calendar['price'] = calendar['price'].str.replace(',','')\n",
    "calendar['price'].fillna(0)\n",
    "calendar['price'] = calendar['price'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {TV,\"Wireless Internet\",Kitchen,\"Free Parking ...\n",
       "1       {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "2       {TV,\"Cable TV\",\"Wireless Internet\",\"Air Condit...\n",
       "3       {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "4       {Internet,\"Wireless Internet\",\"Air Conditionin...\n",
       "5       {\"Cable TV\",\"Wireless Internet\",\"Air Condition...\n",
       "6       {TV,Internet,\"Wireless Internet\",Kitchen,\"Free...\n",
       "7       {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "8       {\"Wireless Internet\",\"Pets live on this proper...\n",
       "9       {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "10      {TV,\"Wireless Internet\",\"Air Conditioning\",Kit...\n",
       "11      {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "12      {\"Cable TV\",\"Wireless Internet\",\"Air Condition...\n",
       "13      {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "14      {Internet,\"Wireless Internet\",Kitchen,\"Free Pa...\n",
       "15      {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "16      {TV,\"Cable TV\",Internet,\"Wireless Internet\",Ki...\n",
       "17      {TV,\"Wireless Internet\",\"Air Conditioning\",Kit...\n",
       "18      {\"Cable TV\",Internet,\"Wireless Internet\",\"Air ...\n",
       "19      {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "20      {Internet,\"Wireless Internet\",\"Air Conditionin...\n",
       "21      {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "22      {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "23      {TV,Internet,\"Wireless Internet\",Kitchen,\"Free...\n",
       "24      {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "25      {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "26      {Internet,\"Wireless Internet\",\"Air Conditionin...\n",
       "27      {\"Wireless Internet\",\"Free Parking on Premises...\n",
       "28      {Internet,\"Wireless Internet\",\"Air Conditionin...\n",
       "29      {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "                              ...                        \n",
       "3555    {\"Air Conditioning\",Kitchen,\"Hot Tub\",\"Indoor ...\n",
       "3556    {\"Wireless Internet\",Kitchen,\"Free Parking on ...\n",
       "3557    {\"Wireless Internet\",\"Air Conditioning\",Kitche...\n",
       "3558    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "3559    {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "3560    {\"Wireless Internet\",Kitchen,\"Free Parking on ...\n",
       "3561    {Internet,\"Wireless Internet\",\"Pets live on th...\n",
       "3562    {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "3563    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "3564    {Internet,\"Wireless Internet\",Kitchen,\"Free Pa...\n",
       "3565    {\"Wireless Internet\",Kitchen,\"Free Parking on ...\n",
       "3566    {TV,\"Wireless Internet\",\"Air Conditioning\",Hea...\n",
       "3567    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "3568    {\"Wireless Internet\",Kitchen,\"Free Parking on ...\n",
       "3569    {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "3570    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "3571    {\"Wireless Internet\",Kitchen,Heating,Washer,Dr...\n",
       "3572    {TV,\"Cable TV\",Internet,\"Wireless Internet\",\"A...\n",
       "3573    {\"Wireless Internet\",Kitchen,Essentials,\"trans...\n",
       "3574    {\"Wireless Internet\",Kitchen,\"Free Parking on ...\n",
       "3575    {Internet,\"Wireless Internet\",\"Air Conditionin...\n",
       "3576    {\"Air Conditioning\",Kitchen,\"Indoor Fireplace\"...\n",
       "3577    {TV,\"Wireless Internet\",Heating,\"Family/Kid Fr...\n",
       "3578    {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "3579    {TV,\"Cable TV\",Internet,\"Wireless Internet\",Ki...\n",
       "3580    {Internet,\"Wireless Internet\",\"Air Conditionin...\n",
       "3581    {TV,Internet,\"Wireless Internet\",\"Air Conditio...\n",
       "3582    {\"translation missing: en.hosting_amenity_49\",...\n",
       "3583    {Kitchen,Gym,\"Family/Kid Friendly\",Washer,Drye...\n",
       "3584    {\"Wireless Internet\",Kitchen,Essentials,\"trans...\n",
       "Name: amenities, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_original['amenities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       TV|Wireless Internet|Kitchen|Free Parking on P...\n",
       "1       TV|Internet|Wireless Internet|Air Conditioning...\n",
       "2       TV|Cable TV|Wireless Internet|Air Conditioning...\n",
       "3       TV|Internet|Wireless Internet|Air Conditioning...\n",
       "4       Internet|Wireless Internet|Air Conditioning|Ki...\n",
       "5       Cable TV|Wireless Internet|Air Conditioning|Ki...\n",
       "6       TV|Internet|Wireless Internet|Kitchen|Free Par...\n",
       "7       TV|Internet|Wireless Internet|Air Conditioning...\n",
       "8       Wireless Internet|Pets live on this property|C...\n",
       "9       TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "10      TV|Wireless Internet|Air Conditioning|Kitchen|...\n",
       "11      TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "12      Cable TV|Wireless Internet|Air Conditioning|Ki...\n",
       "13      TV|Internet|Wireless Internet|Air Conditioning...\n",
       "14      Internet|Wireless Internet|Kitchen|Free Parkin...\n",
       "15      TV|Internet|Wireless Internet|Air Conditioning...\n",
       "16      TV|Cable TV|Internet|Wireless Internet|Kitchen...\n",
       "17      TV|Wireless Internet|Air Conditioning|Kitchen|...\n",
       "18      Cable TV|Internet|Wireless Internet|Air Condit...\n",
       "19      TV|Internet|Wireless Internet|Air Conditioning...\n",
       "20      Internet|Wireless Internet|Air Conditioning|Ki...\n",
       "21      TV|Internet|Wireless Internet|Air Conditioning...\n",
       "22      TV|Internet|Wireless Internet|Air Conditioning...\n",
       "23      TV|Internet|Wireless Internet|Kitchen|Free Par...\n",
       "24      TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "25      TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "26      Internet|Wireless Internet|Air Conditioning|Ki...\n",
       "27      Wireless Internet|Free Parking on Premises|Hea...\n",
       "28      Internet|Wireless Internet|Air Conditioning|Ki...\n",
       "29      TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "                              ...                        \n",
       "3555    Air Conditioning|Kitchen|Hot Tub|Indoor Firepl...\n",
       "3556    Wireless Internet|Kitchen|Free Parking on Prem...\n",
       "3557    Wireless Internet|Air Conditioning|Kitchen|Bre...\n",
       "3558    TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "3559    TV|Internet|Wireless Internet|Air Conditioning...\n",
       "3560    Wireless Internet|Kitchen|Free Parking on Prem...\n",
       "3561    Internet|Wireless Internet|Pets live on this p...\n",
       "3562    TV|Internet|Wireless Internet|Air Conditioning...\n",
       "3563    TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "3564    Internet|Wireless Internet|Kitchen|Free Parkin...\n",
       "3565    Wireless Internet|Kitchen|Free Parking on Prem...\n",
       "3566    TV|Wireless Internet|Air Conditioning|Heating|...\n",
       "3567    TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "3568    Wireless Internet|Kitchen|Free Parking on Prem...\n",
       "3569    TV|Internet|Wireless Internet|Air Conditioning...\n",
       "3570    TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "3571    Wireless Internet|Kitchen|Heating|Washer|Dryer...\n",
       "3572    TV|Cable TV|Internet|Wireless Internet|Air Con...\n",
       "3573    Wireless Internet|Kitchen|Essentials|translati...\n",
       "3574    Wireless Internet|Kitchen|Free Parking on Prem...\n",
       "3575    Internet|Wireless Internet|Air Conditioning|Ki...\n",
       "3576    Air Conditioning|Kitchen|Indoor Fireplace|Heat...\n",
       "3577    TV|Wireless Internet|Heating|Family/Kid Friend...\n",
       "3578    TV|Internet|Wireless Internet|Air Conditioning...\n",
       "3579    TV|Cable TV|Internet|Wireless Internet|Kitchen...\n",
       "3580    Internet|Wireless Internet|Air Conditioning|Ki...\n",
       "3581    TV|Internet|Wireless Internet|Air Conditioning...\n",
       "3582    translation missing: en.hosting_amenity_49|tra...\n",
       "3583    Kitchen|Gym|Family/Kid Friendly|Washer|Dryer|E...\n",
       "3584    Wireless Internet|Kitchen|Essentials|translati...\n",
       "Name: amenities, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = listings_original['amenities'].map(\n",
    "    lambda amns: \"|\".join([amn.replace(\"}\", \"\").replace(\"{\", \"\").replace('\"', \"\")\\\n",
    "                           for amn in amns.split(\",\")]))\n",
    "listings_original['amenities'].map(\n",
    "    lambda amns: \"|\".join([amn.replace(\"}\", \"\").replace(\"{\", \"\").replace('\"', \"\")\\\n",
    "                           for amn in amns.split(\",\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['24-Hour Check-in', 'Air Conditioning', 'Breakfast',\n",
       "       'Buzzer/Wireless Intercom', 'Cable TV', 'Carbon Monoxide Detector',\n",
       "       'Cat(s)', 'Dog(s)', 'Doorman', 'Dryer', 'Elevator in Building',\n",
       "       'Essentials', 'Family/Kid Friendly', 'Fire Extinguisher',\n",
       "       'First Aid Kit', 'Free Parking on Premises',\n",
       "       'Free Parking on Street', 'Gym', 'Hair Dryer', 'Hangers', 'Heating',\n",
       "       'Hot Tub', 'Indoor Fireplace', 'Internet', 'Iron', 'Kitchen',\n",
       "       'Laptop Friendly Workspace', 'Lock on Bedroom Door', 'Other pet(s)',\n",
       "       'Paid Parking Off Premises', 'Pets Allowed',\n",
       "       'Pets live on this property', 'Pool', 'Safety Card', 'Shampoo',\n",
       "       'Smoke Detector', 'Smoking Allowed', 'Suitable for Events', 'TV',\n",
       "       'Washer', 'Washer / Dryer', 'Wheelchair Accessible',\n",
       "       'Wireless Internet', 'translation missing: en.hosting_amenity_49',\n",
       "       'translation missing: en.hosting_amenity_50'], \n",
       "      dtype='<U42')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.concatenate(l2.map(lambda amns: amns.split(\"|\"))))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False,  True,  True, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ..., \n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False,  True]], dtype=bool)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings['amenities'] = listings['amenities'].map(\n",
    "    lambda amns: \"|\".join([amn.replace(\"}\", \"\").replace(\"{\", \"\").replace('\"', \"\")\\\n",
    "                           for amn in amns.split(\",\")]))\n",
    "                           \n",
    "amenities = np.unique(np.concatenate(listings['amenities'].map(lambda amns: amns.split(\"|\"))))[1:]\n",
    "np.array([listings['amenities'].map(lambda amns: amn in amns) for amn in amenities[0:43]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################      LISTINGS      ##################################################\n",
    "#Rob: Here I borrowed code from kaggle, cleaning up the junk in the amenities list, removing parentheses, etc. first\n",
    "#Then I isolated each unique amenity and created column t/f data frames for them, and then eventually concatenated \n",
    "#with original listings data to build features. Just see the features df\n",
    "\n",
    "#Dummy Variables in Listings\n",
    "listings['amenities'] = listings['amenities'].map(\n",
    "    lambda amns: \"|\".join([amn.replace(\"}\", \"\").replace(\"{\", \"\").replace('\"', \"\")\\\n",
    "                           for amn in amns.split(\",\")]))\n",
    "                           \n",
    "amenities = np.unique(np.concatenate(listings['amenities'].map(lambda amns: amns.split(\"|\"))))[1:]\n",
    "amenity_arr = np.array([listings['amenities'].map(lambda amns: amn in amns) for amn in amenities[0:43]])\n",
    "\n",
    "#Listing exploratory\n",
    "#listings['amenities'].map(lambda amns: amns.split(\"|\")).head() #test print?\n",
    "np.unique(np.concatenate(listings['amenities'].map(lambda amns: amns.split(\"|\"))))[1:]\n",
    "\n",
    "#Merged dataset with listings and dummy variables\n",
    "features = pd.concat([listings, pd.DataFrame(data=amenity_arr.T, columns=amenities[0:43])], axis=1)\n",
    "#features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Rob: groupby'ed the calendar listing IDs for total rev, count of bookings/bookigns, and then revenue / booking\n",
    "###########################      CALENDAR SUMMARY FOR MERGING       #########################################\n",
    "#cleanCal = calendar[calendar['available'] == 't']\n",
    "\n",
    "#cleanCal = calendar.groupby('listing_id', as_index = True)['price'].sum().sort_values(['price'], ascending = False)\n",
    "#cleanCal\n",
    "\n",
    "# cleanCal.columns = ['listing_id', 'total_revenue']\n",
    "# cleanCal2 = calendar.groupby('listing_id', as_index = False)['price'].count().sort_values(['price'], ascending = False)\n",
    "# cleanCal2.columns = ['listing_id', 'num_bookings']\n",
    "# cleanCal = cleanCal.merge(cleanCal2)\n",
    "# cleanCal['total_revenue'] = cleanCal['total_revenue'].fillna(0)\n",
    "# cleanCal['revenue_per_booking'] = cleanCal['total_revenue']/cleanCal['num_bookings']\n",
    "# cleanCal['revenue_per_booking'] = cleanCal['revenue_per_booking'].fillna(0)\n",
    "# cleanCal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c36183018ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m###########################      CALENDAR SUMMARY FOR MERGING       #########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mavailable_cal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'available'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmean_price_per_night\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavailable_cal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'listing_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moccupied_cal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'available'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/collinreinking/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \"\"\"\n\u001b[1;32m    963\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGroupByError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/collinreinking/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, numeric_only)\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cython_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3047\u001b[0m         new_items, new_blocks = self._cython_agg_blocks(\n\u001b[0;32m-> 3048\u001b[0;31m             how, numeric_only=numeric_only)\n\u001b[0m\u001b[1;32m   3049\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/collinreinking/anaconda3/lib/python3.5/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_blocks\u001b[0;34m(self, how, numeric_only)\u001b[0m\n\u001b[1;32m   3092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3094\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No numeric types to aggregate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3096\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "#Rob: groupby'ed the calendar listing IDs for total rev, count of bookings/bookigns, and then revenue / booking\n",
    "###########################      CALENDAR SUMMARY FOR MERGING       #########################################\n",
    "available_cal = calendar[calendar['available'] == 't']\n",
    "mean_price_per_night = available_cal.groupby('listing_id', as_index=False)['price'].mean()\n",
    "\n",
    "occupied_cal = calendar[calendar['available'] == 'f']\n",
    "occupied_cal.groupby('listing_id', as_index=False).head()\n",
    "\n",
    "\n",
    "ex = calendar[calendar['listing_id'] == 3075044].sort_values(['date'])\n",
    "ex['day_of_week'] = [d.dayofweek for d in ex['date']]\n",
    "ex_available = ex[ex['available'] == 't']\n",
    "ex_mean_prices = ex_available.groupby('day_of_week', as_index=True)['price'].mean()\n",
    "ex = ex.price.fillna(value = ex.day_of_week.apply(lambda x: ex_mean_prices[int(x)]))\n",
    "ex\n",
    "calendar[calendar['listing_id'] == 3075044].sort_values(['date'])\n",
    "\n",
    "\n",
    "\n",
    "#from datetime import date\n",
    "#[d.dayofweek for d in calendar[calendar['listing_id'] == 3075044]['date']]\n",
    "# cleanCal = calendar.groupby('listing_id', as_index = False)['price'].sum().sort_values(['price'], ascending = False)\n",
    "# cleanCal\n",
    "\n",
    "# cleanCal.columns = ['listing_id', 'total_revenue']\n",
    "# cleanCal2 = calendar.groupby('listing_id', as_index = False)['price'].count().sort_values(['price'], ascending = False)\n",
    "# cleanCal2.columns = ['listing_id', 'num_bookings']\n",
    "# cleanCal = cleanCal.merge(cleanCal2)\n",
    "# cleanCal['total_revenue'] = cleanCal['total_revenue'].fillna(0)\n",
    "# cleanCal['revenue_per_booking'] = cleanCal['total_revenue']/cleanCal['num_bookings']\n",
    "# cleanCal['revenue_per_booking'] = cleanCal['revenue_per_booking'].fillna(0)\n",
    "# cleanCal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dayofweek'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f06f2c313296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'listing_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3075044\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day_of_week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofweek\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mex_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'available'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mex_mean_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex_available\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'day_of_week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f06f2c313296>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcalendar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'listing_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3075044\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'day_of_week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdayofweek\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mex_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'available'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mex_mean_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex_available\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'day_of_week'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dayofweek'"
     ]
    }
   ],
   "source": [
    "#Draft 2\n",
    "\n",
    "ex = calendar[calendar['listing_id'] == 3075044].sort_values(['date'])\n",
    "ex['day_of_week'] = [d.dayofweek for d in ex['date']]\n",
    "ex_available = ex[ex['available'] == 't']\n",
    "ex_mean_prices = ex_available.groupby('day_of_week', as_index=True)['price'].mean()\n",
    "ex = ex.price.fillna(value = ex.day_of_week.apply(lambda x: ex_mean_prices[int(x)]))\n",
    "ex[726]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calendar = temp_cal.copy()\n",
    "temp_cal = calendar.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calendar['modeled_prices'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calendar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73ccadf1533f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         calendar['modeled_prices'][i] = ex[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcalendar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'calendar' is not defined"
     ]
    }
   ],
   "source": [
    "#for each unique listing id\n",
    "#create mean_prices.groupby\n",
    "\n",
    "#n=0\n",
    "print('hi')\n",
    "# for list_id in calendar['listing_id'].unique():\n",
    "#     ex = calendar[calendar['listing_id'] == 3075044].copy()\n",
    "#     ex['day_of_week'] = [d.dayofweek for d in ex['date']]\n",
    "#     ex_available = ex[ex['available'] == 't']\n",
    "#     ex_mean_prices = ex_available.groupby('day_of_week', as_index=True)['price'].mean()\n",
    "#     ex = ex.price.fillna(value = ex.day_of_week.apply(lambda x: ex_mean_prices[int(x)]))\n",
    "#     print(list_id)\n",
    "\n",
    "#     for i in ex.index:\n",
    "#         calendar['modeled_prices'][i] = ex[i]\n",
    "    \n",
    "calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Rob\n",
    "#Initial Master Merging Merging by IDs between cal and \"features\" df\n",
    "listingRev = features.merge(cleanCal, how = 'left', left_on='id', right_on='listing_id')\n",
    "listingRev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neighborhood Summary\n",
    "#The super groupby by neighborhood. Collin feel free to replace neighbourhood_cleased with mainzip for zip\n",
    "\n",
    "#The valuable columns I chose were the revenue metrics, # of reviews, beds, baths, review scores, and then amenities\n",
    "nbr1 = listingRev.groupby('neighbourhood_cleansed', as_index = False)['total_revenue', 'num_bookings', 'number_of_reviews'].sum().sort_values(['total_revenue'])\n",
    "nbr2 = listingRev.groupby('neighbourhood_cleansed', as_index = False)['accommodates', 'bathrooms', 'bedrooms',\n",
    "                        'beds', 'review_scores_rating', 'review_scores_accuracy','review_scores_cleanliness', \n",
    "         'review_scores_checkin', 'review_scores_communication', 'review_scores_location',\n",
    "                        'review_scores_value', ].mean().sort_values(['review_scores_value'])\n",
    "\n",
    "amenityList = ['24-Hour Check-in', 'Air Conditioning', 'Breakfast', 'Buzzer/Wireless Intercom', 'Cable TV', 'Carbon Monoxide Detector','Cat(s)', 'Dog(s)', 'Doorman','Essentials', 'Family/Kid Friendly', 'Fire Extinguisher', 'First Aid Kit', 'Free Parking on Premises', 'Free Parking on Street', 'Gym', 'Hair Dryer', 'Heating', 'Hot Tub','Indoor Fireplace', 'Internet', 'Iron', 'Kitchen','Laptop Friendly Workspace', 'Lock on Bedroom Door', 'Other pet(s)','Paid Parking Off Premises', 'Pets Allowed','Pets live on this property', 'Pool','Smoking Allowed', 'Suitable for Events', 'TV','Washer / Dryer', 'Wheelchair Accessible','Wireless Internet']\n",
    "\n",
    "dummy1 = listingRev.groupby('neighbourhood_cleansed', as_index = False)[amenityList].sum()\n",
    "dummy2 = listingRev.groupby('neighbourhood_cleansed', as_index = False)[amenityList].count()                                                              \n",
    "dummy = dummy1[list(range(1,36))]/dummy2[list(range(1,36))]\n",
    "dummy['neighbourhood_cleansed'] = dummy1[[0]]\n",
    "\n",
    "#Super Merge\n",
    "#Here's the final summary\n",
    "\n",
    "nbhdsummary = nbr1\n",
    "for df in [nbr2, dummy]:\n",
    "    nbhdsummary = nbhdsummary.merge(df)\n",
    "    \n",
    "nbhdsummary.sort_values(['total_revenue'], ascending = False)\n",
    "nbhdsummary.columns.get_loc('Pets Allowed')\n",
    "\n",
    "nbhdsummary.ix[:,nbhdsummary.columns.get_loc('24-Hour Check-in'):nbhdsummary.columns.get_loc('Wheelchair Accessible')].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#understand the datatypes explicitly in the dataset\n",
    "listings.dtypes\n",
    "calendar.dtypes\n",
    "reviews.dtypes\n",
    "\n",
    "\n",
    "#check column names .columns\n",
    "\n",
    "#check headers .head()\n",
    "\n",
    "#check tails .tail()\n",
    "\n",
    "#listings.columns\n",
    "listings.tail()\n",
    "#reviews.head()\n",
    "#listings['neighborhood_overview'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listings_column_names = pd.DataFrame((listings.columns))\n",
    "listings_column_names_list = list(listings.columns)\n",
    "object_first_observation = [listings[x].head(1) for x in listings_column_names_list]\n",
    "observations = pd.DataFrame(object_first_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observations.to_csv('datasample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews['listing_id'].value_counts().plot(kind='hist', figsize = (20,10), fontsize = 16, title = 'Frequency of Reviews')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,250])\n",
    "axes.set_ylim([0,2500])\n",
    "plt.savefig('freq reviews.jpg')\n",
    "#multi_reviews = (reviews['listing_id'].value_counts() > 1)\n",
    "#multi_reviews.value_counts().plot(kind='bar')\n",
    "#data = go.Histogram(x = multi_reviews)\n",
    "#py.iplot(data, filename = 'reviewsmorethan1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#listings['zipcode'].value_counts().plot(kind = 'bar')\n",
    "zipcodes_listings = listings['mainzip'].value_counts()\n",
    "zipcodes_listings.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.scatter(x = listings['host_response_time'], y = listings['review_scores_value'])\n",
    "listings['host_response_time'].value_counts()\n",
    "listings['host_response_time_categories'] = np.nan\n",
    "listings.loc[listings['host_response_time'] == 'within an hour', 'host_response_time_categories'] = 0\n",
    "listings.loc[listings['host_response_time'] == 'within a few hours', 'host_response_time_categories'] = 1\n",
    "listings.loc[listings['host_response_time'] == 'within a day', 'host_response_time_categories'] = 2\n",
    "listings.loc[listings['host_response_time'] == 'a few days or more', 'host_response_time_categories'] = 3\n",
    "\n",
    "#df.loc[df['Sex'] == 'M', 'Sex_int'] = 0\n",
    "#df.loc[df['Sex'] == 'F', 'Sex_int'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x = listings['host_response_time_categories'], y = listings['review_scores_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.scatter(x= listings['zipcode'],y= listings['price'])\n",
    "#plt.figsize()\n",
    "#plt.xlabel('zipcode') #,fontsize = )\n",
    "#plt.ylabel('price')\n",
    "#fig.savefig('scatter.jpg')\n",
    "listings['host_response_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#listings.corr().to_csv('listings_correlations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_amenities = listings['amenities'].str.split(',')\n",
    "list_split_amenities = list(split_amenities)\n",
    "new_list_split_amenities = list()\n",
    "for i in list_split_amenities:\n",
    "    for j in i:\n",
    "        new_list_split_amenities.append(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(new_list_split_amenities)\n",
    "reduced_new_list_split_amenities = list(set(new_list_split_amenities))\n",
    "len(reduced_new_list_split_amenities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#THIS CODE IS INTENDED TO FIND THE REVENUE \n",
    "listings_unique_ids = list(listings['id'].unique())\n",
    "len(listings_unique_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calendar.plot(kind ='panel')\n",
    "#calendar.set_index = calendar['listing_id']\n",
    "\n",
    "#sorted(calendar, key = lambda x: (x['listing_id'], x['date']))\n",
    "calendar.groupby(['listing_id', 'date']).head()\n",
    "calendar.sort_index(ascending = False)\n",
    "\n",
    "#Capture median values\n",
    "calendar[calendar['listing_id'] == 14504422]\n",
    "count_for_id = calendar[(calendar['available'] == 'f') & (calendar['listing_id'] == 14504422)]['available'].count() \n",
    "mean_price =  calendar[(calendar['available'] == 't') & (calendar['listing_id'] == 14504422)]['price'].mean()\n",
    "\n",
    "revenue_wo_cleaning = mean_price * count_for_id\n",
    "revenue_wo_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in \n",
    "count_for_id = calendar[(calendar['available'] == 'f') & (calendar['listing_id'] == 14504422)]['available'].count() \n",
    "mean_price =  calendar[(calendar['available'] == 't') & (calendar['listing_id'] == 14504422)]['price'].mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
